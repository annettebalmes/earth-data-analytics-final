{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pathlib\n",
    "from glob import glob\n",
    "import time\n",
    "import csv\n",
    "import traceback\n",
    "import shutil\n",
    "import psutil\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.appeears as etapp\n",
    "import earthpy.earthexplorer as etee\n",
    "import earthpy.spatial as es\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rioxarray.merge as rxrmerge\n",
    "import xarray as xr\n",
    "import xrspatial\n",
    "import pandas as pd\n",
    "import folium\n",
    "import cartopy.crs as ccrs\n",
    "from zipfile import BadZipFile\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "utm_zone = 32614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62e02a7624d7768be1e0d7717d4b33d6",
     "grade": false,
     "grade_id": "ans-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def create_data_directory(name):\n",
    "    \"\"\"\n",
    "    Create a data directory for data.\n",
    "\n",
    "    This function takes a `name` parameter and creates a directory structure\n",
    "    where NAIP data can be stored. The directory is created inside the\n",
    "    'earth-analytics' directory in the user's home folder.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The name of the directory to be created.\n",
    "\n",
    "    Returns:\n",
    "    - str: The path to the created data directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a variable that stores the path to a directory.\n",
    "    data_path = os.path.join(\n",
    "        pathlib.Path.home(), 'earth-analytics', 'data', 'final', name)\n",
    "\n",
    "    # Create the directory if it doesn't already exist.\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    # Print the path to the data directory.\n",
    "    print(\"Data Directory:\", data_path)\n",
    "\n",
    "    # Return the path to the data directory.\n",
    "    return data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data sub-directory name\n",
    "set_directory_name = \"usa_grassland\"\n",
    "\n",
    "# Run create_data_directory function\n",
    "data_path = create_data_directory(set_directory_name)\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ea109f4d72fe9c96476d2989bc797d3",
     "grade": false,
     "grade_id": "ans-download-neighborhoods",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def check_shapefile_to_gdf(gdf_name, shapefile_url, column_name):\n",
    "    \"\"\"\n",
    "    Check if a GeoDataFrame with a specified name exists. If it exists,\n",
    "    return it; otherwise, download a shapefile from a given URL,\n",
    "    create a GeoDataFrame, and assign it to the specified name.\n",
    "\n",
    "    Parameters:\n",
    "    - gdf_name (str): The name of the GeoDataFrame variable to check/create.\n",
    "    - shapefile_url (str): The URL to download the shapefile.\n",
    "    - column_name (str): The column name to set as the index in the GeoDataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: The existing or newly created GeoDataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to get the GeoDataFrame from the global scope\n",
    "        gdf = globals()[gdf_name]\n",
    "\n",
    "        # If the variable exists, print a message and return it\n",
    "        print(f\"{gdf_name} already exists.\")\n",
    "        return gdf\n",
    "\n",
    "    except KeyError:\n",
    "        # If the variable does not exist, create it\n",
    "        print(f\"{gdf_name} does not exist yet.\")\n",
    "\n",
    "        # Shapefile Location URL\n",
    "        print(\"Downloading Shapefile:\")\n",
    "\n",
    "        # Create GeoDataFrame from the shapefile\n",
    "        gdf = gpd.read_file(shapefile_url)\n",
    "        # Set the specified column as the index\n",
    "        gdf = (\n",
    "            gdf.set_index(column_name)\n",
    "            .to_crs(utm_zone)\n",
    "        )\n",
    "        # Assign the GeoDataFrame to the specified name in the global scope\n",
    "        globals()[gdf_name] = gdf\n",
    "\n",
    "        print(\"Done. Shapefile to Geodataframe.\")\n",
    "\n",
    "        # Return the GeoDataFrame\n",
    "        return gdf\n",
    "\n",
    "# Set up check_shapefile_to_gdf function\n",
    "all_grasslands_url = (\n",
    "    \"https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.NationalGrassland.zip\")                        \n",
    "\n",
    "# Specify the variable name to check, in quotes\n",
    "all_grasslands_gdf_name = \"usa_grasslands_gdf\"\n",
    "\n",
    "#Specify column name of locations\n",
    "gdf_grassland_name_column = 'GRASSLANDN'\n",
    "\n",
    "# Run check_shapefile_to_gdf function\n",
    "all_grasslands_gdf = check_shapefile_to_gdf(\n",
    "    all_grasslands_gdf_name, all_grasslands_url,\n",
    "    gdf_grassland_name_column)\n",
    "\n",
    "all_grasslands_gdf\n",
    "\n",
    "print(all_grasslands_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def site_map(gdf, title, savename):\n",
    "    # Create GeoViews Polygons from the GeoDataFrame\n",
    "    polys = gv.Polygons(gdf.to_crs(4326), vdims=[all_grasslands_gdf.index.name])\n",
    "\n",
    "    # Choropleth map\n",
    "    plot = gv.tile_sources.CartoLight() * polys.opts(\n",
    "        alpha=0.5, fill_alpha=0.7, tools=['hover'],\n",
    "        hover_fill_alpha=0.9, hover_fill_color='red',\n",
    "        title=title, aspect=1\n",
    "    )\n",
    "\n",
    "    # Set plot dimensions\n",
    "    plot.opts(width=500)\n",
    "\n",
    "    # Save the choropleth map as an HTML file\n",
    "    hv.save(plot, f'{savename}.html')\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_map_gdf = all_grasslands_gdf\n",
    "plot_title = 'US National Grasslands'\n",
    "save_plots_as = 'all-grasslands'\n",
    "\n",
    "plot = site_map(site_map_gdf, plot_title, save_plots_as)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoViews Polygons from the GeoDataFrame\n",
    "texas_grasslands_gdf = all_grasslands_gdf.loc[[(\n",
    "    'Lyndon B. Johnson National Grassland')]]\n",
    "\n",
    "print(texas_grasslands_gdf)\n",
    "\n",
    "site_map_gdf = texas_grasslands_gdf\n",
    "plot_title = 'Lyndon B. Johnson National Grassland, Texas, USA.'\n",
    "save_plots_as = 'tx-grasslands'\n",
    "\n",
    "plot = site_map(site_map_gdf, plot_title, save_plots_as)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoViews Polygons from the GeoDataFrame\n",
    "nd_grasslands_gdf = all_grasslands_gdf.loc[[(\n",
    "    'Sheyenne National Grassland')]]\n",
    "print(nd_grasslands_gdf)\n",
    "\n",
    "site_map_gdf = nd_grasslands_gdf\n",
    "plot_title = 'Sheyenne National Grassland, North Dakota, USA.'\n",
    "save_plots_as = 'nd-grasslands'\n",
    "\n",
    "plot = site_map(site_map_gdf, plot_title, save_plots_as)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polaris_to_da(directory_name, file_names, gdf, plot_title):\n",
    "    # Base URL where the .tif files are hosted\n",
    "    base_url = 'http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/ph/mean/100_200/'\n",
    "\n",
    "    # Run create_data_directory function\n",
    "    data_path = create_data_directory(directory_name)\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = Path(data_path)\n",
    "\n",
    "    # List to store downloaded file paths\n",
    "    downloaded_files = []\n",
    "\n",
    "    # Loop through each file name\n",
    "    for file_name in file_names:\n",
    "        # Construct the full URL for the file\n",
    "        file_url = f'{base_url}{file_name}'\n",
    "\n",
    "        # Construct the full output path\n",
    "        if len(file_names) == 1:\n",
    "            output_path = output_directory / file_name\n",
    "        else:\n",
    "            output_path = output_directory / Path(file_name)\n",
    "\n",
    "        # Download the file\n",
    "        response = requests.get(file_url)\n",
    "        if response.status_code == 200:\n",
    "            # Save the file to the output directory\n",
    "            with open(output_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f'Downloaded: {output_path}')\n",
    "            downloaded_files.append(output_path)\n",
    "        else:\n",
    "            print(f'Error downloading {file_name}. Status code: {response.status_code}')\n",
    "\n",
    "    # List to store data arrays\n",
    "    data_arrays = []\n",
    "\n",
    "    # Loop through each downloaded file path\n",
    "    for file_path in downloaded_files:\n",
    "        # Open the .tif file using rioxarray\n",
    "        xarr_data = rxr.open_rasterio(file_path).squeeze()\n",
    "\n",
    "        # Append the xarray DataArray to the list\n",
    "        data_arrays.append(xarr_data)\n",
    "        print(f'Opened and read: {file_path}')\n",
    "\n",
    "    # Merge data arrays into a single dataset\n",
    "    merged_da = (\n",
    "        rxr.merge.merge_arrays(data_arrays)\n",
    "        .rio.reproject(utm_zone)\n",
    "        .rio.clip_box(*gdf.total_bounds)\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plot = merged_da.hvplot(x='x',y='y',rasterize=True).opts(\n",
    "        tools=['hover'], title=plot_title, aspect=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Save the choropleth map as an HTML file\n",
    "    hv.save(plot, f'{directory_name}.html')\n",
    "\n",
    "    return plot, merged_da\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model variables as raster layers covering your study area envelope, including:\n",
    "\n",
    "    Elevation from the SRTM (available from the APPEEARS API)\n",
    "\n",
    "Note: There are two download_elevation functions, the API never works well so the first one will attempt to download the data, and then if fails will manually upload .tif files from the same directory.\n",
    "\n",
    "If you only want to use the manually downloaded data, then the second function should be used. Otherwise, use the first function, and the second as a backup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_elevation(directory_name, gdf, other_da, plot_title):\n",
    "#     from requests.exceptions import HTTPError\n",
    "\n",
    "#     try:\n",
    "#         # Run create_data_directory function\n",
    "#         data_path = create_data_directory(directory_name)\n",
    "#         # Define the parameters\n",
    "\n",
    "#         downloader = etapp.AppeearsDownloader(\n",
    "#             download_key=(directory_name),\n",
    "#             ea_dir=data_path,\n",
    "#             product='SRTMGL1_NC.003',\n",
    "#             layer='SRTMGL1_DEM',\n",
    "#             start_date='02-01-2000',\n",
    "#             end_date='02-21-2000',\n",
    "#             polygon=gdf\n",
    "#         )\n",
    "#         print(\"Downloading Appears SRTM Data...\")\n",
    "\n",
    "#         downloader.download_files()    \n",
    "        \n",
    "#         print(f\"Appears Data Downloaded: {data_path}\")\n",
    "        \n",
    "#         # Extract Filenames\n",
    "#         path_list = glob(os.path.join(downloader.data_dir, '*', '*DEM*.tif'))\n",
    "#         print(path_list)\n",
    "        \n",
    "#         # List to store data arrays\n",
    "#         data_arrays = []\n",
    "\n",
    "#         # Loop through each downloaded file path\n",
    "#         for file_path in path_list:\n",
    "#             # Open the .tif file using rioxarray\n",
    "#             xarr_data = rxr.open_rasterio(file_path, masked=True).squeeze()\n",
    "\n",
    "#             # Append the xarray DataArray to the list\n",
    "#             data_arrays.append(xarr_data)\n",
    "#             print(f'Opened and read: {file_path}')\n",
    "\n",
    "#         # Merge data arrays into a single dataset\n",
    "#         merged_da = (\n",
    "#             rxr.merge.merge_arrays(data_arrays)\n",
    "#             .rio.reproject_match(other_da)\n",
    "            \n",
    "#         )\n",
    "\n",
    "#         plot = xrspatial.aspect(merged_da).hvplot(x='x', y='y', title=plot_title, colormap='colorwheel')\n",
    "\n",
    "#         return plot, merged_da\n",
    "\n",
    "#     except HTTPError as e:\n",
    "#         if e.response.status_code == 500:\n",
    "#             print(\"\\nAPPEARS Internal Server Issue, uploading manually downloaded data.\")\n",
    "            \n",
    "#             # Open the .tif file using rioxarray\n",
    "\n",
    "#             print(str(directory_name))\n",
    "#             if str(directory_name).startswith(\"tx\"):\n",
    "#                 xarr_data = rxr.open_rasterio(\"tx_srtm_data.tif\", masked=True).squeeze()\n",
    "#                 print(f'Opened and read: Texas SRTM Data')\n",
    "\n",
    "#             else:\n",
    "#                 xarr_data = rxr.open_rasterio(\"nd_srtm_data.tif\", masked=True).squeeze()\n",
    "#                 print(f'Opened and read: North Dakota SRTM Data')\n",
    "\n",
    "#             xarr_data = xarr_data.rio.reproject(utm_zone).rio.clip_box(*gdf.total_bounds)\n",
    "\n",
    "#             plot = xrspatial.aspect(xarr_data).hvplot(x='x', y='y', title=plot_title, colormap='colorwheel')\n",
    "\n",
    "#             return plot, xarr_data\n",
    "#         else:\n",
    "#             print(e.response.status_code)\n",
    "\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}. Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_elevation(directory_name, gdf, other_da, plot_title):\n",
    "    from requests.exceptions import HTTPError\n",
    "\n",
    "    print(\"\\nAPPEARS Internal Server Issue, uploading manually downloaded data.\")\n",
    "    \n",
    "    # Open the .tif file using rioxarray\n",
    "\n",
    "    print(str(directory_name))\n",
    "    if str(directory_name).startswith(\"tx\"):\n",
    "        xarr_data = rxr.open_rasterio(\"tx_srtm_data.tif\", masked=True).squeeze()\n",
    "        print(f'Opened and read: Texas SRTM Data')\n",
    "\n",
    "    else:\n",
    "        xarr_data = rxr.open_rasterio(\"nd_srtm_data.tif\", masked=True).squeeze()\n",
    "        print(f'Opened and read: North Dakota SRTM Data')\n",
    "        \n",
    "    xarr_data = xarr_data.rio.reproject_match(other_da)\n",
    "    xarr_data = xarr_data.rio.clip_box(*gdf.total_bounds)\n",
    "\n",
    "    plot = xrspatial.aspect(xarr_data).hvplot(x='x', y='y',title=plot_title, colormap='colorwheel')\n",
    "    # Save the plot as an HTML file\n",
    "    hv.save(plot, f'{directory_name}.html')\n",
    "    \n",
    "    return plot, xarr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model variables as raster layers covering your study area envelope, including:\n",
    "\n",
    "    At least one climate variable from the MACAv2 dataset, accessible from Climate Toolbox. *Undergraduate students may download a single year and scenario; Graduate students should download at least two)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macav2_data_to_da(directory_name, data_bounds, title, gdf, other_da):\n",
    "    # Run create_data_directory function\n",
    "    data_path = create_data_directory(directory_name)\n",
    "\n",
    "    # Define URL to download data from\n",
    "    macav2_data_url = (\n",
    "        \"http://thredds.northwestknowledge.net:8080/thredds/ncss/\"\n",
    "        \"agg_macav2metdata_pr_CCSM4_r6i1p1_historical_1950_2005_CONUS_monthly\"\n",
    "        \".nc?var=precipitation\"\n",
    "        f\"&north={str(data_bounds[0])}\"\n",
    "        f\"&west={str(data_bounds[1])}\"\n",
    "        f\"&east={str(data_bounds[2])}\"\n",
    "        f\"&south={str(data_bounds[3])}\"\n",
    "        \"&horizStride=1&\"\n",
    "        \"time_start=2003-12-15T00%3A00%3A00Z&\"\n",
    "        \"time_end=2005-12-15T00%3A00%3A00Z&\"\n",
    "        \"timeStride=1&accept=netcdf\"\n",
    "    )\n",
    "\n",
    "    # Get netCDF data\n",
    "    macav2_data = requests.get(macav2_data_url)\n",
    "\n",
    "    # Write netCDF data to file\n",
    "    with open('macav2_data.nc', 'wb') as macav2_data_file:\n",
    "        macav2_data_file.write(macav2_data.content)\n",
    "\n",
    "    # Read netCDF data into xarray dataset\n",
    "    data_array = xr.open_dataset('macav2_data.nc').squeeze()\n",
    "\n",
    "    # Correct coordinates: Does not work on a global dataset\n",
    "    data_array = data_array.assign_coords(lon=data_array.lon-360)\n",
    "\n",
    "    # Set the CRS and grab precipitation\n",
    "    precip_da = data_array.precipitation.mean('time')\n",
    "    precip_da = precip_da.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "    precip_da = precip_da.rio.set_spatial_dims('lon', 'lat', inplace=True)\n",
    "    precip_da = precip_da.rio.reproject_match(other_da)\n",
    "    precip_da = precip_da.rio.clip_box(*gdf.total_bounds)\n",
    "    # Plot\n",
    "    plot = precip_da.hvplot(rasterize=True).opts(\n",
    "        tools=['hover'], title=title, aspect=1\n",
    "    )\n",
    "\n",
    "    # Save the plot as an HTML file\n",
    "    hv.save(plot, f'{directory_name}.html')\n",
    "\n",
    "    return plot, precip_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lyndon B. Johnson National Grassland\n",
    "\n",
    "# Download Polaris Data\n",
    "tif_files_to_download = ['lat3334_lon-98-97.tif']\n",
    "directory_save_name = 'tx_polaris_pH'\n",
    "tx_polaris_plot_title = 'Lyndon B. Johnson National Grassland pH range'\n",
    "\n",
    "tx_polaris_plot, tx_polaris_da = polaris_to_da(directory_save_name, tif_files_to_download, texas_grasslands_gdf, tx_polaris_plot_title)\n",
    "\n",
    "# Download AppEARS Data\n",
    "tx_appears_pathname = 'tx_appears_srtm'\n",
    "tx_appears_plot_title = 'Lyndon B. Johnson National Grassland\\nElevation Data'\n",
    "\n",
    "tx_appears_plot, tx_appears_da = download_elevation(\n",
    "    tx_appears_pathname,\n",
    "    texas_grasslands_gdf,\n",
    "    tx_polaris_da,\n",
    "    tx_appears_plot_title)\n",
    "\n",
    "# Derive Slope from Elevation Data\n",
    "tx_slope_da = xrspatial.slope(tx_appears_da.rio.reproject_match(tx_polaris_da))\n",
    "tx_slope_plot = tx_slope_da.hvplot(x='x', y='y', title=\"Lyndon B. Johnson National Grassland Slope\", colormap='viridis_r')\n",
    "\n",
    "# Download MACAV2 Data\n",
    "tx_macav2_path = 'macav2_aggregated_monthly_historical'\n",
    "tx_n_w_e_s_bounds = [33.45, -97.8, -97.45, 33.2]\n",
    "tx_macav2_title = 'Lyndon B. Johnson National Grassland\\nMean Monthly Aggregated Precipitation over Time\\n2003 to 2005'\n",
    "\n",
    "tx_macav2_plot, tx_macav2_da = macav2_data_to_da(tx_macav2_path, tx_n_w_e_s_bounds, tx_macav2_title, texas_grasslands_gdf, tx_polaris_da)\n",
    "\n",
    "# Combine plots into a single layout\n",
    "layout = (tx_polaris_plot + tx_appears_plot + tx_slope_plot + tx_macav2_plot).cols(1)\n",
    "\n",
    "# Save the layout to HTML files\n",
    "hv.save(layout, 'tx_combined_data_plots.html')\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sheyenne National Grassland\n",
    "\n",
    "# Download Polaris Data\n",
    "tif_files_to_download = ['lat4647_lon-97-96.tif', 'lat4647_lon-98-97.tif']\n",
    "directory_save_name = 'nd_polaris_pH'\n",
    "nd_polaris_plot_title = 'Sheyenne National Grassland pH range'\n",
    "\n",
    "nd_polaris_plot, nd_polaris_da = polaris_to_da(directory_save_name, tif_files_to_download, nd_grasslands_gdf, nd_polaris_plot_title)\n",
    "\n",
    "# Download AppEARS Data\n",
    "nd_appears_pathname = 'nd_appears_srtm'\n",
    "nd_appears_plot_title = 'Sheyenne National Grassland\\nElevation Data'\n",
    "\n",
    "nd_appears_plot, nd_appears_da = download_elevation(\n",
    "    nd_appears_pathname,\n",
    "    nd_grasslands_gdf,\n",
    "    nd_polaris_da,\n",
    "    nd_appears_plot_title)\n",
    "\n",
    "# Derive Slope from Elevation Data\n",
    "nd_slope_da = xrspatial.slope(nd_appears_da.rio.reproject_match(nd_polaris_da))\n",
    "nd_slope_plot = nd_slope_da.hvplot(x='x', y='y', title=\"Sheyenne National Grassland Slope\", colormap='viridis_r')\n",
    "\n",
    "# Download MACAV2 Data\n",
    "nd_macav2_path = 'macav2_aggregated_monthly_historical'\n",
    "nd_n_w_e_s_bounds = [46.58, -97.5, -96.9, 46.1]\n",
    "nd_macav2_title = 'Sheyenne National Grassland\\nMean Monthly Aggregated Precipitation over Time\\n2003 to 2005'\n",
    "\n",
    "nd_macav2_plot, nd_macav2_da = macav2_data_to_da(nd_macav2_path, nd_n_w_e_s_bounds, nd_macav2_title, nd_grasslands_gdf, nd_polaris_da)\n",
    "\n",
    "# Combine plots into a single layout\n",
    "layout = (nd_polaris_plot + nd_appears_plot + nd_slope_plot + nd_macav2_plot).cols(1)\n",
    "\n",
    "# Save the layout to HTML files\n",
    "hv.save(layout, 'nd_combined_data_plots.html')\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate at least one derived topographic variable (slope or aspect) to use in your model. You probably will wish to use the xarray-spatial library, which is available in the latest earth-analytics-python environment (but will need to be installed/updated if you are working on your own machine). Note that calculated slope may not be correct if you are using a CRS with units of degrees; you should re-project into a projected coordinate system with units of meters, such as the appropriate UTM Zone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harmonize your data - make sure that the grids for each of your layers match up. Check out the ds.rio.reproject_match() method from rioxarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_set_crs(datasets, reference_dataset):\n",
    "    updated_datasets = []\n",
    "    target_crs = reference_dataset.rio.crs if isinstance(\n",
    "        reference_dataset, xr.DataArray) else reference_dataset.crs\n",
    "    \n",
    "    print(\"Making necessary changes...\")\n",
    "\n",
    "    for ds in datasets:\n",
    "        if isinstance(ds, xr.DataArray):\n",
    "            if ds.rio.crs != target_crs:\n",
    "                ds = ds.rio.set_crs(target_crs)\n",
    "\n",
    "            # Clip to the bounds of reference_dataset\n",
    "            if isinstance(reference_dataset, gpd.GeoDataFrame):\n",
    "                bounds = reference_dataset.total_bounds\n",
    "                # Create a bounding box geometry from the bounds\n",
    "                bbox = box(bounds[0], bounds[1], bounds[2], bounds[3])\n",
    "                # Clip the DataArray using the bounding box\n",
    "                ds = ds.rio.clip_box(*bbox.bounds)\n",
    "\n",
    "        elif isinstance(ds, gpd.GeoDataFrame):\n",
    "            if ds.crs != target_crs:\n",
    "                ds = ds.to_crs(target_crs)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported dataset type. Supported types\"\n",
    "                    \" are xarray.DataArray and geopandas.GeoDataFrame.\")\n",
    "\n",
    "        updated_datasets.append(ds)\n",
    "\n",
    "    print(\"All data is harmonized and clipped.\")\n",
    "\n",
    "    return updated_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tx_data_arrays = check_and_set_crs([texas_grasslands_gdf, tx_appears_da, tx_macav2_da], tx_polaris_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_nd_data_arrays = check_and_set_crs([nd_grasslands_gdf, nd_appears_da, nd_macav2_da], nd_polaris_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research S. nutans, and find out what optimal values are for each variable you are using (e.g. soil pH, slope, and current climatological annual precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_nutans_pH_min = 4.8      # pH low range\n",
    "s_nutans_pH_max = 8.0      # pH high range\n",
    "\n",
    "s_nutans_slope_min = 10    # percentage low slope range\n",
    "s_nutans_slope_max = 40    # percentage low slope range\n",
    "\n",
    "s_nutans_precip_min = 28   # precip low range\n",
    "s_nutans_precip_max = 114  # precip low range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data in each dataarray, assign a value from 0 to 1 for how close that grid square is to the optimum range (1=optimal, 0=incompatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_da(data_array, optimum_min, optimum_max):\n",
    "    # Calculate proximity to the optimum range for each grid square\n",
    "    proximity = 1 - abs((data_array - optimum_min) / (optimum_max - optimum_min))\n",
    "\n",
    "    # Clip proximity values to ensure they are between 0 and 1\n",
    "    proximity = proximity.clip(0, 1)\n",
    "\n",
    "    return proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine your layers by multiplying them together. This will give you a single suitability number for each square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TX\n",
    "\n",
    "# Optimum Values\n",
    "tx_polaris_optimal_da = binary_da(tx_polaris_da, s_nutans_pH_min, s_nutans_pH_max)\n",
    "tx_slope_optimal_da = binary_da(tx_slope_da, s_nutans_slope_min, s_nutans_slope_max)\n",
    "tx_macav2_optimal_da = binary_da(tx_macav2_da, s_nutans_precip_min, s_nutans_precip_max)\n",
    "final_tx_optimal = tx_polaris_optimal_da * tx_slope_optimal_da * tx_macav2_optimal_da\n",
    "\n",
    "# Create individual plots\n",
    "tx_pH = tx_polaris_optimal_da.hvplot(x='x', y='y', title=\"Lyndon B. Johnson National Grassland pH\\nOptimized for pH Between 4.8 and 8.0\", colormap='viridis_r')\n",
    "tx_slope = tx_slope_optimal_da.hvplot(x='x', y='y', title=\"Lyndon B. Johnson National Grassland Slope\\nOptimized for Percentage Between 10 and 40\", colormap='viridis_r')\n",
    "tx_precip = tx_macav2_optimal_da.hvplot(title=\"Lyndon B. Johnson National Grassland Precipitation\\nOptimized for Between 28mm and 114mm\", colormap='viridis_r')\n",
    "tx_final = final_tx_optimal.hvplot(x='x', y='y', title=\"Lyndon B. Johnson National Grassland\\nSorghastrum nutans Habitat Suitability Model\", colormap='viridis_r')\n",
    "\n",
    "# Combine plots into a single layout\n",
    "layout = (tx_pH + tx_slope + tx_precip + tx_final).cols(1)\n",
    "\n",
    "# Save the layout to HTML files\n",
    "hv.save(layout, 'tx_combined_optimal_plots.html')\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ND\n",
    "\n",
    "# Optimum Values\n",
    "nd_polaris_optimal_da = binary_da(nd_polaris_da, s_nutans_pH_min, s_nutans_pH_max)\n",
    "nd_slope_optimal_da = binary_da(nd_slope_da, s_nutans_slope_min, s_nutans_slope_max)\n",
    "nd_macav2_optimal_da = binary_da(nd_macav2_da, s_nutans_precip_min, s_nutans_precip_max)\n",
    "final_nd_optimal = nd_polaris_optimal_da * nd_slope_optimal_da * nd_macav2_optimal_da\n",
    "\n",
    "\n",
    "# Create individual plots\n",
    "nd_pH = nd_polaris_optimal_da.hvplot(x='x', y='y', title=\"Sheyenne National Grassland pH\\nOptimized for pH Between 4.8 and 8.0\", colormap='viridis_r')\n",
    "nd_slope = nd_slope_optimal_da.hvplot(x='x', y='y', title=\"Sheyenne National Grassland Slope\\nOptimized for Percentage Between 10 and 40\", colormap='viridis_r')\n",
    "nd_precip = nd_macav2_optimal_da.hvplot(title=\"Sheyenne National Grassland Precipitation\\nOptimized for Between 28mm and 114mm\", colormap='viridis_r')\n",
    "nd_final = final_nd_optimal.hvplot(x='x', y='y', title=\"Sheyenne National Grassland\\nSorghastrum nutans Habitat Suitability Model\", colormap='viridis_r')\n",
    "\n",
    "# Combine plots into a single layout\n",
    "layout = (nd_pH + nd_slope + nd_precip + nd_final).cols(1)\n",
    "\n",
    "# Save the layout to HTML files\n",
    "hv.save(layout, 'nd_combined_optimal_plots.html')\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
